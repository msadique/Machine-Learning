{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest CoverType dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members\n",
    "Mohd Sadique A20380442"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description\n",
    "================================================================================================================================================================================================================================================================\n",
    "Predicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types). \n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. \n",
    "\n",
    "Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. \n",
    "\n",
    "As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4). \n",
    "\n",
    "The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.) Cache la Poudre would probably be more unique than the others, due to its relatively low elevation range and species composition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt, where\n",
    "from pylab import scatter, show, legend, xlabel, ylabel\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The Clean Version of the input File is being used for testing\n",
    "input_file = \"testdata.csv\"\n",
    "df = pd.read_csv(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The Data Shape of the input File \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data used for testing has 500049 tuples and 11 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect Slope</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal Dist.</th>\n",
       "      <th>Vertical Distance</th>\n",
       "      <th>Hor. Dist. To road</th>\n",
       "      <th>HillShade_9am</th>\n",
       "      <th>HillShade_Noon</th>\n",
       "      <th>HillShade_3pm</th>\n",
       "      <th>Hor. Dist. To Fire</th>\n",
       "      <th>CoverType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2579</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>-15</td>\n",
       "      <td>67</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>140</td>\n",
       "      <td>6031</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2606</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>270</td>\n",
       "      <td>5</td>\n",
       "      <td>633</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "      <td>138</td>\n",
       "      <td>6256</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2605</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>7</td>\n",
       "      <td>573</td>\n",
       "      <td>222</td>\n",
       "      <td>230</td>\n",
       "      <td>144</td>\n",
       "      <td>6228</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2617</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>240</td>\n",
       "      <td>56</td>\n",
       "      <td>666</td>\n",
       "      <td>223</td>\n",
       "      <td>221</td>\n",
       "      <td>133</td>\n",
       "      <td>6244</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2612</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>11</td>\n",
       "      <td>636</td>\n",
       "      <td>228</td>\n",
       "      <td>219</td>\n",
       "      <td>124</td>\n",
       "      <td>6230</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect Slope   Slope   Horizontal Dist.   Vertical Distance  \\\n",
       "0       2596             51       3                258                  0   \n",
       "1       2590             56       2                212                 -6   \n",
       "2       2804            139       9                268                 65   \n",
       "3       2785            155      18                242                118   \n",
       "4       2595             45       2                153                 -1   \n",
       "5       2579            132       6                300                -15   \n",
       "6       2606             45       7                270                  5   \n",
       "7       2605             49       4                234                  7   \n",
       "8       2617             45       9                240                 56   \n",
       "9       2612             59      10                247                 11   \n",
       "\n",
       "   Hor. Dist. To road  HillShade_9am  HillShade_Noon  HillShade_3pm  \\\n",
       "0                 510            221             232            148   \n",
       "1                 390            220             235            151   \n",
       "2                3180            234             238            135   \n",
       "3                3090            238             238            122   \n",
       "4                 391            220             234            150   \n",
       "5                  67            230             237            140   \n",
       "6                 633            222             225            138   \n",
       "7                 573            222             230            144   \n",
       "8                 666            223             221            133   \n",
       "9                 636            228             219            124   \n",
       "\n",
       "   Hor. Dist. To Fire  CoverType  \n",
       "0                6279          5  \n",
       "1                6225          5  \n",
       "2                6121          2  \n",
       "3                6211          2  \n",
       "4                6172          5  \n",
       "5                6031          2  \n",
       "6                6256          5  \n",
       "7                6228          5  \n",
       "8                6244          5  \n",
       "9                6230          5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 1s in the Target  0.203\n",
      "Probability of 2s in the Target  0.576\n",
      "Probability of 3s in the Target  0.043\n",
      "Probability of 4s in the Target  0.043\n",
      "Probability of 5s in the Target  0.048\n",
      "Probability of 6s in the Target  0.043\n",
      "Probability of 7s in the Target  0.043\n"
     ]
    }
   ],
   "source": [
    "# Counting the Total Number of Target \n",
    "totalTarget = df[\"CoverType\"].count()\n",
    "\n",
    "# Count of 0s in the target\n",
    "zeroCount = df[(df[\"CoverType\"] == 0)].count()[0]\n",
    "\n",
    "# Count of 1s in the target\n",
    "oneCount = df[(df[\"CoverType\"] == 1)].count()[1]\n",
    "\n",
    "# Count of 2s in the target\n",
    "twoCount = df[(df[\"CoverType\"] == 2)].count()[2]\n",
    "\n",
    "# Count of 3s in the target\n",
    "threeCount = df[(df[\"CoverType\"] == 3)].count()[3]\n",
    "\n",
    "# Count of 4s in the target\n",
    "fourCount = df[(df[\"CoverType\"] == 4)].count()[4]\n",
    "\n",
    "# Count of 5s in the target\n",
    "fiveCount = df[(df[\"CoverType\"] == 5)].count()[5]\n",
    "\n",
    "# Count of 6s in the target\n",
    "sixCount = df[(df[\"CoverType\"] == 6)].count()[6]\n",
    "\n",
    "# Count of 7s in the target\n",
    "sevenCount = df[(df[\"CoverType\"] == 7)].count()[7]\n",
    "\n",
    "#probabilities of the counts \n",
    "probOne = oneCount / totalTarget\n",
    "probTwo = twoCount / totalTarget\n",
    "probThree = threeCount / totalTarget\n",
    "probFour = fourCount / totalTarget\n",
    "probFive = fiveCount / totalTarget\n",
    "probSix = sixCount / totalTarget\n",
    "probSeven = sevenCount / totalTarget\n",
    "\n",
    "totalTarget = df[\"CoverType\"].count()\n",
    "\n",
    "print(\"Probability of 1s in the Target \", '%0.3f'%(probOne))\n",
    "print(\"Probability of 2s in the Target \", '%0.3f'%(probTwo))\n",
    "print(\"Probability of 3s in the Target \", '%0.3f'%(probThree))\n",
    "print(\"Probability of 4s in the Target \", '%0.3f'%(probFour))\n",
    "print(\"Probability of 5s in the Target \", '%0.3f'%(probFive))\n",
    "print(\"Probability of 6s in the Target \", '%0.3f'%(probSix))\n",
    "print(\"Probability of 7s in the Target \", '%0.3f'%(probSeven))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since probability for 2s in the target is higher than others, we'll use 0.576 as out baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = df.values\n",
    "# Features\n",
    "X = list(array[:,0:10])\n",
    "# Target\n",
    "Y = list(array[:,10])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.70, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So below we can see that Logistic Regression accuracy is best when argument C = 2.0 i.e. 0.75447**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with CR =  8 : 0.75395(+/- 0.01193)\n",
      "Accuracy with CR =  4 : 0.75430(+/- 0.01094)\n",
      "Accuracy with CR =  2 : 0.75447(+/- 0.01213)\n",
      "Accuracy with CR =  1 : 0.75441(+/- 0.01206)\n",
      "Accuracy with CR =  0.1 : 0.75421(+/- 0.01083)\n",
      "Accuracy with CR =  0.01 : 0.75398(+/- 0.01122)\n",
      "Accuracy with CR =  0.001 : 0.75213(+/- 0.01149)\n",
      "Accuracy with CR =  0.002 : 0.75310(+/- 0.01159)\n",
      "Accuracy with CR =  0.0001 : 0.74616(+/- 0.00876)\n",
      "Accuracy with CR =  1e-05 : 0.73146(+/- 0.01151)\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy of LOGISTIC REGRESSION using CROSS_VAL_SCORE\n",
    "C= [8,4,2,1,0.1,0.01,0.001,0.002,0.0001,0.00001]\n",
    "for i in C: \n",
    "    clf = LogisticRegression(C = i, max_iter = 1000, random_state=0)\n",
    "    scoresLR = cross_val_score(clf,X_train,Y_train,cv=10,scoring='accuracy')\n",
    "    print(\"Accuracy with C = \",i,\": %0.5f(+/- %0.5f)\" %(scoresLR.mean(), scoresLR.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Accuracy with Decision Tree Classifier is 0.89353**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Decision Tree: 0.89353 (+/- 0.00977)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "scoresDT = cross_val_score(dtree,X_train,Y_train,cv=10,scoring='accuracy')\n",
    "print(\"Accuracy with Decision Tree: %0.5f (+/- %0.5f)\" % (scoresDT.mean(), scoresDT.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Accuracy with Naive Bayes is 0.69869**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Gaussian Naive Bayes: 0.69869 (+/- 0.01266)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gauss = GaussianNB()\n",
    "scores = cross_val_score(gauss,X_train,Y_train,cv=10,scoring='accuracy')\n",
    "print(\"Accuracy with Gaussian Naive Bayes: %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Accuracy with MLPC Classifier is when learning_rate = 0.006 i.e. 0.80208**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with MLPC Classifier with 1 : 0.57598 (+/- 0.00067)\n",
      "Accuracy with MLPC Classifier with 0.1 : 0.57598 (+/- 0.00067)\n",
      "Accuracy with MLPC Classifier with 0.01 : 0.77824 (+/- 0.05321)\n",
      "Accuracy with MLPC Classifier with 0.001 : 0.71244 (+/- 0.14857)\n",
      "Accuracy with MLPC Classifier with 0.002 : 0.72115 (+/- 0.05858)\n",
      "Accuracy with MLPC Classifier with 0.003 : 0.69509 (+/- 0.18500)\n",
      "Accuracy with MLPC Classifier with 0.004 : 0.69856 (+/- 0.13267)\n",
      "Accuracy with MLPC Classifier with 0.005 : 0.76531 (+/- 0.06178)\n",
      "Accuracy with MLPC Classifier with 0.006 : 0.80208 (+/- 0.01917)\n",
      "Accuracy with MLPC Classifier with 0.0001 : 0.75903 (+/- 0.02978)\n",
      "Accuracy with MLPC Classifier with 1e-05 : 0.76954 (+/- 0.02184)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "L = [1,0.1,0.01,0.001,0.002,0.003,0.004,0.005,0.006,0.0001,0.00001, 0.000001]\n",
    "for l in L: \n",
    "    MLPC = MLPClassifier(random_state=0, learning_rate='adaptive',max_iter=10000, learning_rate_init=l)\n",
    "    scoresMLPC = cross_val_score(MLPC,X_train,Y_train,cv=10,scoring='accuracy')\n",
    "    print(\"Accuracy with MLPC Classifier with\",l,\": %0.5f (+/- %0.5f)\" % (scoresMLPC.mean(), scoresMLPC.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Accuracy with Support Vector Machines is 0.86523**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC()\n",
    "scores = cross_val_score(clf,X_train,Y_train,cv=10,scoring='accuracy')\n",
    "print(\"Accuracy with Support Vector Machines: %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the various models in the order of increasing accuracy:**\n",
    "\n",
    "1) Logistic Regression : 0.61068\n",
    "\n",
    "2) Decision Tree Classifier: 0.89353\n",
    "\n",
    "3) Naive Bayes : 0.63920\n",
    "\n",
    "4) MLPC Classifer : 0.85161 \n",
    "\n",
    "5) Support Vector Machines : 0.86523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "predict = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "a=accuracy_score(Y_test,predict)\n",
    "p=precision_score(Y_test,predict,average=None)\n",
    "r=recall_score(Y_test,predict,average=None)\n",
    "print(\"Accuracy Score : %0.5f(+/- %0.5f)\" %(a.mean(), a.std()*2))\n",
    "print(\"Precision Score : %0.5f(+/- %0.5f)\" %(p.mean(), p.std()*2))\n",
    "print(\"Recall Score : %0.5f(+/- %0.5f)\" %(r.mean(), r.std()*2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
